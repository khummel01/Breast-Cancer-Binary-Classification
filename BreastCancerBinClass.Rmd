---
title: "Breast Cancer Binary Classification"
output: html_document
  toc: yes

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE}
# Libraries
library(tidyr)
library(ggplot2)
library(corrplot)
library ("MASS")
library(car)
library(lmtest)
library(magrittr)
library (rpart)
library(ROCR)

```

# Title 
Predicting Malignancy of Breast Mass

# Abstract 
This report examines 569 breast masses using logistic regression methods. The primary goal is to determine what predictor variables are most effective at predicting the malignancy of a breast mass, as well as to see if there is a certain combination of predictor variables that most accurately predicts malignancy. The ten predictor variables were radius (mean of distances from center to points on the perimeter), texture (standard deviation of gray-scale values), perimeter, area, smoothness (local variation in radius lengths), compactness (perimeter^2/area – 1), concavity (severity of concave portions of the contour), symmetry, and fractal dimension (“coastline approximation”-1). We have thirty total predictor variables because the mean, standard error, and "worst" value are taken for each of these ten variables. The worst value is the largest mean of the value for each predictor. The response variable was the diagnosis of malignant (represented by 1) or benign (represented by 0). 

# Introduction

# Data Characteristics

```{r echo=FALSE}
# Read in the data
folder = "/Users/katie/repos/Breast-Cancer-Binary-Classification"
cancer = read.csv(paste (folder, "breastcancer.csv", sep="/"),header=T)
par (mfrow = c(1, 2))
# hist (quality, xlab="Quality", main="Histogram of Quality")
# boxplot (quality, horizontal = T, xlab="Quality", main="Boxplot of Quality")
```

Cleaning the data:

```{r}
# Removing columns id and X
cancer$id <- NULL
cancer$X <- NULL
cancer$diagnosis2 = 3
# Reassigning malignant masses as 1 and benign 0
cancer$diagnosis2[cancer$diagnosis == "M"] = 1
cancer$diagnosis2[cancer$diagnosis == "B"] = 0
cancer$diagnosis <- NULL

attach (cancer)

```

```{r}
table(diagnosis2)

```

```{r}
 barplot (table (ifelse (cancer2$diagnosis2==1, "Benign", "Malignant")), main="Count of Benign and Malignant Tumors", xlab="Diagnosis", ylab="# of Images", ylim=c(0, 450))

```

```{r}
cancer %>% gather() %>% head()
ggplot(gather(cancer), aes(value)) + 
    geom_histogram(bins = 8) + 
    facet_wrap(~key, scales = 'free_x')

```

The table of benign and malignant tumor counts and bar plot above show that out of the 569 images of breast masses collected, 357 of them were benign and 212 malignant. As indicated by the distribution plot of each variable above, it appears that predictors area mean, area standard error, area "worst", compactness mean, compactness standard error, compactness worst, concave points mean, concavity mean, concavity standard error, perimeter worst, radius worst, smoothness standard error, symmetry standard error, and texture standard error are clearly right-skewed. Transformations are needed to make these distributions more symmetric.

```{r}
# Adding the log transformed predictors to the data set
cancer$log.area_mean = log(area_mean)
cancer$log.area_se = log(area_se)
cancer$log.area_worst = log(area_worst)
cancer$log.compactness_mean = log(compactness_mean)
cancer$log.compactness_se = log(compactness_se)
cancer$log.compactness_worst = log(compactness_worst)
cancer$log.concave.points_mean = log(10*(concave.points_mean) + 0.01)
cancer$log.concavity_mean = log(10*(concavity_mean) + 0.01)
cancer$log.concavity_se = log(10*(concavity_se) + 0.01)
cancer$log.perimeter_worst = log(perimeter_worst)
cancer$log.radius_worst = log(radius_worst)
cancer$log.smoothness_se = log(smoothness_se)
cancer$log.symmetry_se = log(symmetry_se)
cancer$log.texture_se = log(texture_se)

# Creating a dataframe with just the log transformed predictors
transformed_predictors = data.frame(cancer$log.area_mean, cancer$log.area_se, cancer$log.area_worst, cancer$log.compactness_mean, cancer$log.compactness_se, cancer$log.compactness_worst, cancer$log.concave.points_mean, cancer$log.concavity_mean, cancer$log.concavity_se, cancer$log.perimeter_worst, cancer$log.radius_worst, cancer$log.smoothness_se, cancer$log.symmetry_se, cancer$log.texture_se)

# Plotting the log transformed predictors
transformed_predictors %>% gather() %>% head()
ggplot(gather(transformed_predictors), aes(value)) + 
    geom_histogram(bins = 8) + 
    facet_wrap(~key, scales = 'free_x')

# Creating a dataframe of just transformed predictors and predictors that did not need transformations
cancer2 <- cancer
cancer2 <- subset(cancer2, select=-c(area_mean, area_se, area_worst, compactness_mean, compactness_se, compactness_worst, concave.points_mean, concavity_mean, concavity_se, perimeter_worst, radius_worst, smoothness_se, symmetry_se, texture_se))

detach(cancer)
attach(cancer2)

```

The severly right-skewed predictors now have a more symmetric distribution with the log transformation applied. We will use these log transformed predictors as we proceed with our analysis.

## Plots of Significant Predictors




## Correlations and Scatter Plots

We will first take a look at the coefficent of determination values in our data set to ascertain which predictors are highly correlated with one another.

```{r}
cancer2data_frame = data.frame(cancer2$diagnosis2, cancer2$radius_mean, cancer2$texture_mean, cancer2$perimeter_mean, cancer2$smoothness_mean, cancer2$symmetry_mean, cancer2$fractal_dimension_mean, cancer2$radius_se, cancer2$perimeter_se, cancer2$concave.points_se, cancer2$fractal_dimension_se, cancer2$texture_worst, cancer2$smoothness_worst, cancer2$concavity_worst, cancer2$concave.points_worst, cancer2$symmetry_worst, cancer2$fractal_dimension_worst, cancer2$log.area_mean, cancer2$log.area_se, cancer2$log.area_worst, cancer2$log.compactness_mean, cancer2$log.compactness_se, cancer2$log.compactness_worst, cancer2$log.concave.points_mean, cancer2$log.concavity_mean, cancer2$log.concavity_se, cancer2$log.perimeter_worst, cancer2$log.radius_worst, cancer2$log.smoothness_se, cancer2$log.symmetry_se, cancer2$log.texture_se)

cormat = cor(cancer2data_frame, use="complete.obs")
round (cormat, 2)

```

There appears to be many variables that are highly correlated with one another. The predictors that are highly correlated with diagnosis are concavity_worst (r=0.66), concave.points_worst (r=0.79), log.area_mean (r=0.73), log.area_se (r=0.72), log.area_worst (r=0.78), log.compactness_mean (r=0.60), log.concave.points_mean (r=0.68), log.concavity_mean (r=0.63), log.perimeter_worst (r=0.79), and log.radius_worst (r=0.79). The majority of the predictors are positively correlated with one another. The one negative correlation worth mentioning is between fractual dimension mean and radius worst and even this correlation is relatively weak with an r value of -0.29. Most stiking are the correlations between radius, perimeter, and area. For all three features computed for each image, mean, standard error, and "worst" (or largest mean of the three largest values), radius, perimeter, and area were all extremely correlated with one another, each achieving a r value of 0.96 or above. Perimeter mean and radius mean as well as area worst and radius worst even achieved a correlation of 1.00 

We will now look at the scatter plots to visualize these significant correlations.

Because there are many predictors in our data set, we will look at the correlation plots in groups of the cell nucleus's mean, standard error, and "worst" to more easily see the interactions happening amongst each grouping.

Mean Predictors:

```{r fig.height=8, fig.width=8}
cancer2.mean = data.frame(cancer2$radius_mean, cancer2$texture_mean, cancer2$perimeter_mean, cancer2$log.area_mean, cancer2$smoothness_mean, cancer2$log.compactness_mean, cancer2$log.concavity_mean, cancer2$log.concave.points_mean, cancer2$symmetry_mean, cancer2$fractal_dimension_mean)

pairs(cancer2.mean, pch=1)

```

Quite noteably, radius and perimeter mean, radius mean and log(area mean), and perimeter mean and log(area mean) are very highly correlated. Radius mean and perimeter mean appear to be linearly correlated whereas radius mean and log(area mean) and perimeter mean log(area mean) are non-linearly correlated. Log(compactness mean) and log(concavity mean), log(compactness mean) and log(concave points mean), and log(concave points mean) and log(concavity mean) also demonstrate strong correlations, although much more spread is present between these predictors than between radius mean with either perimeter mean or log(area mean).

Standard Error Predictors:

```{r fig.height=8, fig.width=8}
cancer2.se = data.frame(cancer2$radius_se, cancer2$log.texture_se, cancer2$perimeter_se, cancer2$log.area_se, cancer2$log.smoothness_se, cancer2$log.compactness_se, cancer2$log.concavity_se, cancer2$concave.points_se, cancer2$log.symmetry_se, cancer2$fractal_dimension_se)

pairs(cancer2.se, pch=1)

```

Area standard error and perimeter standard error, radius standard error and log(area standard error), and perimeter standard error and log(area standard error) are extremely correlated. Log(compactness standard error), log(concavity standard error),and concave points standard error are also highly correlated with one another, but with much more spread and noteably log(concavity standard error) and concave points standard error do not appear to be linearly correlated. Additionally, log(compactness standard error) and fractal dimension standard error and log(concavity standard error) and fractal dimension standard error are strongly correlated, but are not very linear.

"Worst" Predictors:

```{r fig.height=8, fig.width=8}
cancer2.worst = data.frame(cancer2$log.radius_worst, cancer2$texture_worst, cancer2$log.perimeter_worst, cancer2$log.area_worst, cancer2$smoothness_worst, cancer2$log.compactness_worst, cancer2$concavity_worst, cancer2$concave.points_worst, cancer2$symmetry_worst, cancer2$fractal_dimension_worst)

pairs(cancer2.worst, pch=1)

```

Log(radius worst) and log(perimeter worst), log(radius worst) and log(area worst), and log(perimeter worst) and log(area worst) are extremely correlated. These correlations are also very linear. There also appears to be a strong correlation between log(compactness worst) and concavity worst, log(compactness worst) and concave points worst, concavity worst and concave points worst, and compactness worst and fractal dimension worst although these correlations are not linear.


Additional note, none of the predictor variables in breast cancer dataset are categorical, nor should be.

#ASK: WHAT PREDICTOR TO USE IN PLOT?
```{r}
plot (jitter (cancer2$diagnosis2, 0.1) ~ cancer2$texture_worst, cancer2$radius_mean, xlab="Age, years", ylab="Disease Status (0=No, 1=Yes)")
# lines (lowess (log.area_mean, diagnosis2), col='darkgreen')

```

# First-order Tree Regression Model

Fitting a model with all 30 predictors was not computationally viable using logistic regression as all 30 predictors caused the model to overfit the data, so we decided to fit a first-order model using tree regression instead.

```{r}
cancer.tree_model <- rpart(cancer2$diagnosis2 ~ cancer2$radius_mean + cancer2$texture_mean + cancer2$perimeter_mean + cancer2$smoothness_mean + cancer2$symmetry_mean + cancer2$fractal_dimension_mean + cancer2$radius_se + cancer2$perimeter_se + cancer2$concave.points_se + cancer2$fractal_dimension_se + cancer2$texture_worst + cancer2$smoothness_worst + cancer2$concavity_worst + cancer2$concave.points_worst + cancer2$symmetry_worst + cancer2$fractal_dimension_worst + cancer2$log.area_mean + cancer2$log.area_se + cancer2$log.area_worst + cancer2$log.compactness_mean + cancer2$log.compactness_se + cancer2$log.compactness_worst + cancer2$log.concave.points_mean + cancer2$log.concavity_mean + cancer2$log.concavity_se + cancer2$log.perimeter_worst + cancer2$log.radius_worst + cancer2$log.smoothness_se + cancer2$log.symmetry_se + cancer2$log.texture_se)

par (mfrow=c(1,1))
plot(cancer.tree_model, uniform = TRUE, margin = 0.1, branch = 0.5,
 compress = TRUE)
text(cancer.tree_model)
```

This tree says that log(radius worst) is the single most important predictor in determining if a breast mass is malignant or not. Other significant predictors include texture mean, concave points worst, and texture worst. A breast mass is most likely to be malignant if its log(radius worst) is greater than 2.821 and has a concave points worst value greater than 0.1358. The probability of a breast mass being malignant given these conditions is 98.5%. A breast mass is least likely to be cancerous if its log(radius worst) is less than 2.821 and its texture mean is less than 16.11; this is a probability of 1.16%. There is about a 50/50 chance that the breast mass is malignant if its log(radius worst) is less than 2.821 and its texture mean is greater than 16.11. 

### ROC Curve of First-order Model

```{r}
roc.tree = function (fit) {
 if (fit$method=="anova") {
 fitvals = predict(fit)
 }
 else {
 fitvals = predict(fit) [,2]
 }

 pred1 <- prediction(fitvals, fit$y)
 perf1 <- performance(pred1,"tpr","fpr")
 auc1 <- performance(pred1,"auc")@y.values[[1]]
 plot(perf1, lwd=2, col=2)
 abline(0,1)
 legend(0.25, 0.2, c(paste ("AUC=", round(auc1, 2), sep="")),
 cex=0.8, lwd=2, col=2)
 roc.table = cbind.data.frame (pred1@tn, pred1@fp, pred1@fn, pred1@tp,
 pred1@cutoffs, perf1@x.values,
perf1@y.values)
 roc.table$spec = 1 - perf1@x.values[[1]]
 roc.table$ppv = pred1@tp[[1]] / (pred1@tp[[1]] + pred1@fp[[1]])
 roc.table$npv = pred1@tn[[1]] / (pred1@tn[[1]] + pred1@fn[[1]])
 roc.table$pctcorr = (pred1@tn[[1]] + pred1@tp[[1]]) /
 (pred1@tn[[1]] + pred1@tp[[1]] + pred1@fn[[1]] + pred1@fp[[1]])
 roc.table$optdist = sqrt ((perf1@x.values[[1]] - 0)^2 +
 (perf1@y.values[[1]] - 1)^2)
 names (roc.table) = c("TN", "FP", "FN", "TP", "Cutoff", "FPR", "TPR",
"Spec",
 "PPV", "NPV", "PctCorr", "OptDist")
 return (roc.table)
}
roc1 = roc.tree (cancer.tree_model)

```

The ROC curve for the tree regression model looks very good. Our tree model can accurately distinguish between whether a breast mass is malignant or benign.

### Correlations of Significant Predictors

```{r}
cancer.tree_model_df = data.frame(cancer2$diagnosis2, cancer2$log.radius_worst, cancer2$texture_mean, cancer2$concave.points_worst, cancer2$texture_worst)
pairs(cancer.tree_model_df, pch=1)

```

Predictors texture mean and texture worst have a strong positive linear correlation at r=0.91. Log(radius worst) and concave points mean also have a significant positive linear correlation with one another, however this correlation is not as strong with an r value of 0.79.

### Residuals of the First-order Model

```{r}
# par (mfrow=c(1,2))
# plot (cancer.tree_model, which=c(1,5))

plot (predict(cancer.tree_model), residuals(cancer.tree_model), main="Diagnosis vs
Predicted")
abline (0, 0, col='red')
resid.se = sd (residuals (cancer.tree_model))
legend (0.7, 0.8, c(paste ("Resid SE=", round (resid.se, 4))), cex=0.8)

```

#todo: ask why only 10 points are appearing on the plot

# Model Selection

## Stepwise Regression on First-order Model

In the first-order model, we used tree regression to avoid overfitting the data. When we attempted a "both" stepwise regression model with all 30 predictors, we again encountered the issue of overfitting the data. To resolve this problem, we first took out predictors perimeter and area for all three features (mean, standard error, and "worst"), because of how highly correlated they are with radius, and attempted to fit the model again, but encountered the same error. At this point we switched from a "both" stepwise regression model, to "forward" regression, then proceeded to resolve the overfitting error through manually taking out the offending predictor until the stepwise could proceed without any warnings of the model overfitting the data. The collection of predictors that gave us no errors when attemping to fit a model using "forward" stepwise regression is what is displayed in the code below.

```{r}
min.model = glm(diagnosis2 ~ 1, family=binomial, data=cancer2)

fwd.model = step(min.model, direction='forward', scope=(~ smoothness_mean + symmetry_mean + fractal_dimension_mean + radius_se  + concave.points_se + concavity_worst + fractal_dimension_worst + log.compactness_mean  + log.compactness_worst + log.concavity_mean + log.concavity_se  + log.radius_worst + log.smoothness_se + log.symmetry_se + log.texture_se))

```

```{r}
summary(fwd.model)
```

The forward stepwise regression ended with a total of six predictors that resulted in the lowest AIC value of 123.95, an improvement from the first-order model with an AIC of 145.85. These predictors are log.radius_worst, concavity_worst, smoothness_mean, log.texture_se, log.compactness_mean, and fractal_dimension_worst. Log.radius_worst, concavity_worst, smoothness_mean, log.texture_se, log.compactness_mean are all significant at $\alpha = .001$ with fractal_dimension_worst significant at $\alpha = .01$. The most significant predictor is log.radius_worst with a p-value of 3.62e-14. 

For each additional unit of any one predictor in the forward stepwise regreesion model, the odds of the breast mass being malignant increases by over 100%.

### Plot of Stepwise Model

```{r}
#Celia

```

### Residuals of Stepwise Model

```{r}
par (mfrow=c(1,2))
plot (fwd.model, which=c(1,5))

```

The Residuals vs Fitted plot looks reasonable and it appears that the model fits the data very well as indicated by the flat Lowess line and how close to zero it resides. Interestingly, observation 298 was highlighted as a potential outlier again, but 136 and 42 were not from the previous model. Instead, observations 14 and 41 are now indicated as potential outliers along with 298. The Residuals vs Leverage Plot suggests the presence of a few influential points in the data as indicated by the presence of Cook's distance contour lines on the graph. However, although points 298, 69, and 529 come close to the contour lines so they do not concern us.

### ROC Curve and AUC Analysis of Best First-order Model

```{r}
#Celia
par (mfrow=c(1,1))
pred1 <- prediction(fwd.model$fitted.values, fwd.model$y)
perf1 <- performance(pred1,"tpr","fpr")
auc1 <- performance(pred1,"auc")@y.values[[1]]
auc1

plot(perf1, lwd=2, col=2)
abline(0,1)
legend(0.6, 0.3, c(paste ("AUC=", round (auc1, 4), sep="")),   lwd=2, col=2)

# Extract the X and Y values from the ROC plot, as well as the probability cutoffs
roc.x = slot (perf1, "x.values") [[1]]
roc.y = slot (perf1, "y.values") [[1]]
cutoffs = slot (perf1, "alpha.values") [[1]]

auc.table = cbind.data.frame(cutoff=pred1@cutoffs,tp=pred1@tp, fp=pred1@fp, tn=pred1@tn, fn=pred1@fn)
names (auc.table) = c("Cutoff", "TP", "FP", "TN", "FN")
auc.table$sensitivity = auc.table$TP / (auc.table$TP + auc.table$FN)
auc.table$specificity = auc.table$TN / (auc.table$TN + auc.table$FP)
auc.table$FalsePosRate = 1 - auc.table$specificity
auc.table$sens_spec = auc.table$sensitivity + auc.table$specificity

# Find the row(s) in the AUC table where sensitivity + specificity is maximized
auc.best = auc.table [auc.table$sens_spec == max (auc.table$sens_spec),]
auc.best

# Plot the maximum point(s) on the ROC plot
points (auc.best$FalsePosRate, auc.best$sensitivity, cex=1.3)
```

## Fitting a Model with Interactions
a.) Include interaction effects from Step 5
b.) Apply stepwise regression using the step function
c.) What are the results?
d.) Which model(s) seems(s) to be best?

```{r}
# Laura

```
## Interpretation
a.) Meaning/interpretation of regression parameters
b.) Make some example response predictions with confidence intervals and interpret those results

The following tables show some example predicted probabilities and their confidence intervals for subjects.
```{r}
# Change variables!!!

# With logistic regression, the predict function does not provide confidence limits, even with the interval= option.  Instead, we request the se.fit=T option and calculate our own limits on the logist scale, and then back-transform to the probability scale.
preds = predict (m.both, se.fit = T)
pred.df = cbind.data.frame (disout.data, as.data.frame (preds))

pred.df$lwr = pred.df$fit - 1.96 * pred.df$se.fit
pred.df$upr = pred.df$fit + 1.96 * pred.df$se.fit

pred.df$fit.pr = round (exp (pred.df$fit) / (1 + exp (pred.df$fit)), 3)
pred.df$lwr.pr = round (exp (pred.df$lwr) / (1 + exp (pred.df$lwr)), 3)
pred.df$upr.pr = round (exp (pred.df$upr) / (1 + exp (pred.df$upr)), 3)

# Selected subjects in their 20's
pred.df [c(30,47,78,21,16,11), c(2,5:7,14:16)]

```

The following table summarizes the observed and predicted classifications of malignancy using the first-order model:
```{r}
# Change variables!!!

pred.df$pred.dis = ifelse (pred.df$fit.pr >= auc.best$Cutoff[1], "Pred.Yes", "Pred.No")
table (pred.df$disease, pred.df$pred.dis)
```
The following table summarizes the observed and predicted classifications of malignancy using the stepwise model:
```{r}
# Change variables!!!

pred.df$pred.dis = ifelse (pred.df$fit.pr >= auc.best$Cutoff[1], "Pred.Yes", "Pred.No")
table (pred.df$disease, pred.df$pred.dis)
```
The following table summarizes the observed and predicted classifications of malignancy using the interaction effects:
```{r}
# Change variables!!!

pred.df$pred.dis = ifelse (pred.df$fit.pr >= auc.best$Cutoff[1], "Pred.Yes", "Pred.No")
table (pred.df$disease, pred.df$pred.dis)
```
