---
title: "Breast Cancer Binary Classification"
output: html_document
  toc: yes

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE}
# Libraries
library(tidyr)
library(ggplot2)
library(corrplot)
library ("MASS")
library(car)
library(lmtest)
library(magrittr)
```

# Abstract 

# Introduction

# Data Characteristics

```{r echo=FALSE}
# Read in the data
folder = "/Users/katie/repos/Breast-Cancer-Binary-Classification"
cancer = read.csv(paste (folder, "breastcancer.csv", sep="/"),header=T)
par (mfrow = c(1, 2))
# hist (quality, xlab="Quality", main="Histogram of Quality")
# boxplot (quality, horizontal = T, xlab="Quality", main="Boxplot of Quality")
```

Cleaning the data:

```{r}
# Removing columns id and X
cancer$id <- NULL
cancer$X <- NULL
cancer$diagnosis2 = 3
# Reassigning malignant masses as 1 and benign 0
cancer$diagnosis2[cancer$diagnosis == "M"] = 1
cancer$diagnosis2[cancer$diagnosis == "B"] = 0
cancer$diagnosis <- NULL

attach (cancer)

```

```{r}
table(diagnosis2)

```

```{r}
 barplot (table (ifelse (cancer2$diagnosis2==1, "Benign", "Malignant")), main="Count of Benign and Malignant Tumors", xlab="Diagnosis", ylab="# of Images", ylim=c(0, 450))

```

```{r}
cancer %>% gather() %>% head()
ggplot(gather(cancer), aes(value)) + 
    geom_histogram(bins = 8) + 
    facet_wrap(~key, scales = 'free_x')

```

The table of benign and malignant tumor counts and bar plot above show that out of the 569 images of breast masses collected, 357 of them were benign and 212 malignant. As indicated by the distribution plot of each variable above, it appears that predictors area mean, area standard error, area "worst", compactness mean, compactness standard error, compactness worst, concave points mean, concavity mean, concavity standard error, perimeter worst, radius worst, smoothness standard error, symmetry standard error, and texture standard error are clearly right-skewed. Transformations are needed to make these distributions more symmetric.

```{r}
# Adding the log transformed predictors to the data set
cancer$log.area_mean = log(area_mean)
cancer$log.area_se = log(area_se)
cancer$log.area_worst = log(area_worst)
cancer$log.compactness_mean = log(compactness_mean)
cancer$log.compactness_se = log(compactness_se)
cancer$log.compactness_worst = log(compactness_worst)
cancer$log.concave.points_mean = log(10*(concave.points_mean) + 0.01)
cancer$log.concavity_mean = log(10*(concavity_mean) + 0.01)
cancer$log.concavity_se = log(10*(concavity_se) + 0.01)
cancer$log.perimeter_worst = log(perimeter_worst)
cancer$log.radius_worst = log(radius_worst)
cancer$log.smoothness_se = log(smoothness_se)
cancer$log.symmetry_se = log(symmetry_se)
cancer$log.texture_se = log(texture_se)

# Creating a dataframe with just the log transformed predictors
transformed_predictors = data.frame(cancer$log.area_mean, cancer$log.area_se, cancer$log.area_worst, cancer$log.compactness_mean, cancer$log.compactness_se, cancer$log.compactness_worst, cancer$log.concave.points_mean, cancer$log.concavity_mean, cancer$log.concavity_se, cancer$log.perimeter_worst, cancer$log.radius_worst, cancer$log.smoothness_se, cancer$log.symmetry_se, cancer$log.texture_se)

# Plotting the log transformed predictors
transformed_predictors %>% gather() %>% head()
ggplot(gather(transformed_predictors), aes(value)) + 
    geom_histogram(bins = 8) + 
    facet_wrap(~key, scales = 'free_x')

# Creating a dataframe of just transformed predictors and predictors that did not need transformations
cancer2 <- cancer
cancer2 <- subset(cancer2, select=-c(area_mean, area_se, area_worst, compactness_mean, compactness_se, compactness_worst, concave.points_mean, concavity_mean, concavity_se, perimeter_worst, radius_worst, smoothness_se, symmetry_se, texture_se))

detach(cancer)
attach(cancer2)

```

The severly right-skewed predictors now have a more symmetric distribution with the log transformation applied. We will use these log transformed predictors as we proceed with our analysis.

## Plots of Significant Predictors




## Correlations and Scatter Plots

We will first take a look at the coefficent of determination values in our data set to ascertain which predictors are highly correlated with one another.

```{r}
# NOTE: THIS IS COMMENTED OUT JUST TO SAVE SPACE. DO NOT DELETE.
cancer2data_frame = data.frame(cancer2$diagnosis2, cancer2$radius_mean, cancer2$texture_mean, cancer2$perimeter_mean, cancer2$smoothness_mean, cancer2$symmetry_mean, cancer2$fractal_dimension_mean, cancer2$radius_se, cancer2$perimeter_se, cancer2$concave.points_se, cancer2$fractal_dimension_se, cancer2$texture_worst, cancer2$smoothness_worst, cancer2$concavity_worst, cancer2$concave.points_worst, cancer2$symmetry_worst, cancer2$fractal_dimension_worst, cancer2$log.area_mean, cancer2$log.area_se, cancer2$log.area_worst, cancer2$log.compactness_mean, cancer2$log.compactness_se, cancer2$log.compactness_worst, cancer2$log.concave.points_mean, cancer2$log.concavity_mean, cancer2$log.concavity_se, cancer2$log.perimeter_worst, cancer2$log.radius_worst, cancer2$log.smoothness_se, cancer2$log.symmetry_se, cancer2$log.texture_se)

cormat = cor(cancer2data_frame, use="complete.obs")
round (cormat, 2)

```

There appears to be many variables that are highly correlated with one another. The predictors that are highly correlated with diagnosis are concavity_worst (r=0.66), concave.points_worst (r=0.79), log.area_mean (r=0.73), log.area_se (r=0.72), log.area_worst (r=0.78), log.compactness_mean (r=0.60), log.concave.points_mean (r=0.68), log.concavity_mean (r=0.63), log.perimeter_worst (r=0.79), and log.radius_worst (r=0.79). The majority of the predictors are positively correlated with one another. The one negative correlation worth mentioning is between fractual dimension mean and radius worst and even this correlation is relatively weak with an r value of -0.29. Most stiking are the correlations between radius, perimeter, and area. For all three features computed for each image, mean, standard error, and "worst" (or largest mean of the three largest values), radius, perimeter, and area were all extremely correlated with one another, each achieving a r value of 0.96 or above. Perimeter mean and radius mean as well as area worst and radius worst even achieved a correlation of 1.00 

We will now look at the scatter plots to visualize these significant correlations.

Because there are many predictors in our data set, we will look at the correlation plots in groups of the cell nucleus's mean, standard error, and "worst" to more easily see the interactions happening amongst each grouping.

Mean Predictors:

```{r fig.height=8, fig.width=8}
cancer2.mean = data.frame(cancer2$radius_mean, cancer2$texture_mean, cancer2$perimeter_mean, cancer2$log.area_mean, cancer2$smoothness_mean, cancer2$log.compactness_mean, cancer2$log.concavity_mean, cancer2$log.concave.points_mean, cancer2$symmetry_mean, cancer2$fractal_dimension_mean)

pairs(cancer2.mean, pch=1)

```

Quite noteably, radius and perimeter mean, radius mean and log(area mean), and perimeter mean and log(area mean) are very highly correlated. Radius mean and perimeter mean appear to be linearly correlated whereas radius mean and log(area mean) and perimeter mean log(area mean) are non-linearly correlated. Log(compactness mean) and log(concavity mean), log(compactness mean) and log(concave points mean), and log(concave points mean) and log(concavity mean) also demonstrate strong correlations, although much more spread is present between these predictors than between radius mean with either perimeter mean or log(area mean).

Standard Error Predictors:

```{r fig.height=8, fig.width=8}
cancer2.se = data.frame(cancer2$radius_se, cancer2$log.texture_se, cancer2$perimeter_se, cancer2$log.area_se, cancer2$log.smoothness_se, cancer2$log.compactness_se, cancer2$log.concavity_se, cancer2$concave.points_se, cancer2$log.symmetry_se, cancer2$fractal_dimension_se)

pairs(cancer2.se, pch=1)

```

Area standard error and perimeter standard error, radius standard error and log(area standard error), and perimeter standard error and log(area standard error) are extremely correlated. Log(compactness standard error), log(concavity standard error),and concave points standard error are also highly correlated with one another, but with much more spread and noteably log(concavity standard error) and concave points standard error do not appear to be linearly correlated. Additionally, log(compactness standard error) and fractal dimension standard error and log(concavity standard error) and fractal dimension standard error are strongly correlated, but are not very linear.

"Worst" Predictors:

```{r fig.height=8, fig.width=8}
cancer2.worst = data.frame(cancer2$log.radius_worst, cancer2$texture_worst, cancer2$log.perimeter_worst, cancer2$log.area_worst, cancer2$smoothness_worst, cancer2$log.compactness_worst, cancer2$concavity_worst, cancer2$concave.points_worst, cancer2$symmetry_worst, cancer2$fractal_dimension_worst)

pairs(cancer2.worst, pch=1)

```

Log(radius worst) and log(perimeter worst), log(radius worst) and log(area worst), and log(perimeter worst) and log(area worst) are extremely correlated. These correlations are also very linear. There also appears to be a strong correlation between log(compactness worst) and concavity worst, log(compactness worst) and concave points worst, concavity worst and concave points worst, and compactness worst and fractal dimension worst although these correlations are not linear.


Additional note, none of the predictor variables in breast cancer dataset are categorical, nor should be.

#ASK: WHAT PREDICTOR TO USE IN PLOT?
```{r}
plot (jitter (cancer2$diagnosis2, 0.1) ~ cancer2$texture_worst, cancer2$radius_mean, xlab="Age, years", ylab="Disease Status (0=No, 1=Yes)")
# lines (lowess (log.area_mean, diagnosis2), col='darkgreen')

```

# First-order Logistic Regression Model

Fitting a model with all 30 predictors was not computationally viable as all 30 predictors caused the model to overfit the data. We first manually removed predictors perimeter and area for all three features (mean, standard error, and "worst") because of their high correlation with radius, then from there, removed predictors based on p-values until we no longer received warning that the model was being overfit, so we ended up with only four predictors in our model.

```{r}
model1 <- glm(diagnosis2 ~ concave.points_se + fractal_dimension_se + fractal_dimension_worst + log.radius_worst, family=binomial, data=cancer2)

summary(model1)
exp (model1$coefficients)
```

Because we manually removed predictors based on p-values to avoid overfitting our model, all four predictors in our first-order model are significant at $\alpha = .001$ with log.radius_worst being the most signicant predictor with a p-value of 3.26e-16. With each additional unit of fractal_dimension_se we expect the odds of the breast mass being malignant to increase by 0%. With each additional unit of concave.points_se, fractal_dimension_worst, and log.radius_worst the odds of the breast mass being malignant decrease by 0%.

### Plot of First-order Model

```{r}
# Celia

# plot(cancer $age, jitter(disout.data$disease, .1), col=ifelse (sector==0, "red", "blue"))
# ageseq = seq (min(age), max(age), by=1)
# fitprob0 = predict (disease.logit, data.frame (age=ageseq, socio="Upper", sector=0), type='response')
# lines (ageseq, fitprob0, col='red')
# fitprob1 = predict (disease.logit, data.frame (age=ageseq, socio="Upper", sector=1),
# type='response') lines (ageseq, fitprob1, col='blue')
# legend(1,0.9,c('Sector 0','Sector 1'),lty=c(1,1),lwd=c(2.5,2.5), cex=0.8, col=c("red","blue"))

ggplot(cancer2, aes(x=, y=diagnosis2)) + geom_point() + 
  stat_smooth(method="glm", method.args=list(family="binomial"), se=FALSE)

```






```{r}
sumModel1 = summary (model1, correlation = T)
corrplot (sumModel1$correlation, method="number", number.cex=0.6)
model1.data.frame = data.frame(cancer2$diagnosis2, cancer2$concave.points_se, cancer2$fractal_dimension_se, cancer2$fractal_dimension_worst, cancer2$log.radius_worst)
pairs(model1.data.frame, pch=1)

```

There are no two predictors that are highly co-linear, however, predictors fractal_dimension_se and concave.points_se and fractal_dimension_worst and fractal_dimension_se are highly correlated at r=-0.79 and r=-0.75 respectively. 

### Residuals of the First-order Model

```{r}
par (mfrow=c(1,2))
plot (model1, which=c(1,5))

```

The Residuals vs Fitted plot provides evidence that the model fits the data fairly well since the Lowess line is relatively flat and close to zero, although there is a a small spike in the Lowess line towards the middle of the graph, however this is normal for residuals vs fitted plots of logistic regression models. This plot suggests the presence of three outliers, observations 298, 42, and 136. The Residuals vs Leverage Plot suggests the presence of a few influential points in the data as indicated by the presence of Cook's distance contour lines on the graph. However, although points 298 and 42 come close to the contour lines, they are not outside of these lines and thus, are not of concern to us.

We will refit the model a few more times before deciding whether or not observations 298, 42, and 136 really are outliers and need to be removed from the data.

# Model Selection

## Stepwise Regression on First-order Model

In the first-order model, we had to slim down the number of predictors beforing fitting the model, as doing otherwise resulted in a warning stating that the given model overfit the data. This same warning appeared when we attempted a "both" stepwise regression model with all 30 predictors. To resolve this issue, we first took out predictors perimeter and area for all three features (mean, standard error, and "worst"), because of how highly correlated they are with radius, and attempted to fit the model again, but encountered the same error. At this point we switched from a "both" stepwise regression model, to "forward" regression, then proceeded to resolve the error through manually taking out the offending predictor until the stepwise could proceed without any warnings of the model overfitting the data. The collection of predictors that gave us no errors when attemping to fit a model using "forward" stepwise regression is what is displayed in the code below.

```{r}
min.model = glm(diagnosis2 ~ 1, family=binomial, data=cancer2)

fwd.model = step(min.model, direction='forward', scope=(~ smoothness_mean + symmetry_mean + fractal_dimension_mean + radius_se  + concave.points_se + concavity_worst + fractal_dimension_worst + log.compactness_mean  + log.compactness_worst + log.concavity_mean + log.concavity_se  + log.radius_worst + log.smoothness_se + log.symmetry_se + log.texture_se))

```

```{r}
summary(fwd.model)
```

The forward stepwise regression ended with a total of six predictors that resulted in the lowest AIC value of 123.95, an improvement from the first-order model with an AIC of 145.85. These predictors are log.radius_worst, concavity_worst, smoothness_mean, log.texture_se, log.compactness_mean, and fractal_dimension_worst. Log.radius_worst, concavity_worst, smoothness_mean, log.texture_se, log.compactness_mean are all significant at $\alpha = .001$ with fractal_dimension_worst significant at $\alpha = .01$. The most significant predictor is log.radius_worst with a p-value of 3.62e-14. 

For each additional unit of any one predictor in the forward stepwise regreesion model, the odds of the breast mass being malignant increases by over 100%.

### Plot of Stepwise Model

```{r}
#Celia

```

### Residuals of Stepwise Model

```{r}
par (mfrow=c(1,2))
plot (fwd.model, which=c(1,5))

```

The Residuals vs Fitted plot looks reasonable and it appears that the model fits the data very well as indicated by the flat Lowess line and how close to zero it resides. Interestingly, observation 298 was highlighted as a potential outlier again, but 136 and 42 were not from the previous model. Instead, observations 14 and 41 are now indicated as potential outliers along with 298. The Residuals vs Leverage Plot suggests the presence of a few influential points in the data as indicated by the presence of Cook's distance contour lines on the graph. However, although points 298, 69, and 529 come close to the contour lines so they do not concern us.

### ROC Curve and AUC Analysis of Best First-order Model

```{r}
#Celia

```

## Fitting a Model with Interactions
a.) Include interaction effects from Step 5
b.) Apply stepwise regression using the step function
c.) What are the results?
d.) Which model(s) seems(s) to be best?

```{r}
# Laura

```

